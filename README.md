# Jay Patel ‚Äì 1 Month Data Science Internship Plan

This repository tracks my learning progress during my 1-month data science internship.

---

## Week 1 ‚Äì Python Fundamentals (05/21/25 to 05/25/25)

| Topic                         | Status      | Date      |
|-------------------------------|-------------|-----------|
| Introduction + Basics          | Completed ‚úÖ | 05/21/25  |
| Control Flow, Functions, Data Structures | Completed ‚úÖ | 05/22/25  |
| File Handling & Exception Handling | Completed ‚úÖ | 05/23/25  |
| Object-Oriented Programming   |Completed ‚úÖ | 05/24/25  |
| Modules, Libraries & Projects |Completed ‚úÖ | 05/25/25  |

---

## Week 2 ‚Äì Foundations: NumPy, Pandas & Data Visualization (05/26/25 to 05/30/25)

| Topic                     | Status      | Date      |
|---------------------------|-------------|-----------|
| NumPy Basics              | Completed ‚úÖ | 05/26/25  |
| Advanced NumPy            | Completed ‚úÖ | 05/27/25  |
| Pandas Basics & Operations| Completed ‚úÖ | 05/28/25  |
| Data Cleaning             | Completed ‚úÖ| 05/29/25  |
| Matplotlib & Seaborn Visuals | Completed ‚úÖ| 05/30/25  |

---

## Week 3 ‚Äì Statistics, EDA & Machine Learning Introduction (06/02/25 to 06/06/25)

| Topic                         | Status      | Date      |
|-------------------------------|-------------|-----------|
| Descriptive Statistics         | Completed ‚úÖ | 06/02/25  |
| Probability Essentials & Hypothesis Testing | Completed ‚úÖ | 06/03/25  |
| Exploratory Data Analysis (EDA) Practice |Completed ‚úÖ | 06/04/25  |
| Machine Learning Basics + Scikit Learn |Completed ‚úÖ | 06/05/25  |
| Linear & Logistic Regression    |Completed ‚úÖ | 06/06/25  |

---

## Week 4 ‚Äì ML Models & Projects (06/09/25 to 06/13/25)

| Topic                        | Status      | Date      |
|------------------------------|-------------|-----------|
| KNN & Decision Trees          | ‚úÖ Completed | 06/09/25  |
| Random Forest & Model Evaluation | ‚úÖ Completed | 06/10/25  |
| KMeans Clustering             |‚úÖ Completed | 06/11/25  |
| Feature Engineering, Pipelines & Tuning | ‚úÖ Completed | 06/12/25  |
| NLP Techniques                | ‚úÖ Completed | 06/13/25  |

---
## Week 5 ‚Äì BERT Model & Final Project (06/16/25 to 06/20/25)

| Topic                                                                 | Status       | Date      |
|-----------------------------------------------------------------------|--------------|-----------|
| Load and preprocess dataset for deep learning                         | ‚úÖ Completed  | 06/16/25  |
| Clean and tokenize text using BERT tokenizer                          | ‚úÖ Completed  | 06/17/25  |
| Encode labels for binary classification (real vs. fake)               | ‚úÖ Completed  | 06/17/25  |
| Load pre-trained BERT model & prepare for fine-tuning (Hugging Face) | ‚úÖ Completed  | 06/18/25  |
| Fine-tune BERT model for fake news classification                     | ‚è≥ In Progress| 06/19/25  |
| Evaluate performance: accuracy, precision, recall, F1-score           | ‚è≥ Planned    | 06/20/25  |
| Plot confusion matrix & compare with traditional ML models            | ‚è≥ Planned    | 06/20/25  |

---



### Project Description

I will apply the skills learned during weeks 1 to 4 in this end-to-end project:

- Use Python fundamentals, data structures, and control flow for preprocessing logic  
- Use Pandas, NumPy, Matplotlib, and Seaborn for data cleaning, exploration, and visualization  
- Implement NLP techniques such as TF-IDF to convert text into features  
- Train and evaluate classical machine learning models using scikit-learn, including:  
  - Logistic Regression  
  - Naive Bayes  
  - Random Forest  

**Dataset:** LIAR dataset  
**Dataset Details:**  
- Contains 12,800+ labeled political statements from PolitiFact  
- Labels: pants-fire, false, barely-true, half-true, mostly-true, true  
- For binary classification, labels grouped as:  
  - Fake (1): pants-fire, false, barely-true, half-true  
  - Real (0): mostly-true, true  


After evaluating the performance of the three classical machine learning models, which resulted in comparatively lower accuracies as shown in the chart below:

![image](https://github.com/user-attachments/assets/9b304993-c4bc-40c9-bc95-1b7d01f74178)

You can view the full implementation of these classical models in the following Jupyter Notebook:  
‚û°Ô∏è [Classical Models Implementation ‚Äì `LIAR.ipynb`](./LIAR.ipynb)


I have decided to implement a fine-tuned BERT model to improve the classification performance.

## Notes

- Status Legend:
  - ‚úÖ Completed
  - üöß In Progress
  - ‚è≥ Not Started

- This README will be updated weekly to track progress.

---

## Contact

**Jay Patel**  
Email: int-jay.k.patel@outamationlabs.com  
       22it094@charusat.edu.in
       jpatel23092004@gmail.com
GitHub:(https://github.com/JayyPatel239/Internshipp_LearningPhase))
        (https://github.com/Jayypatell23)
        
